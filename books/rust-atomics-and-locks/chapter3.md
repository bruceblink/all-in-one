---
sidebar_position: 6
typora-root-url: ./..\..\static
---

# 第 3 章 内存序（Memory Ordering）

在[第2章]()中，我们简要提到了内存序的概念。本章我们将深入探讨这一主题，了解所有可用的内存序选项，最重要的是，明确在何种情况下使用哪一种。

## **重排序与优化**（Reordering and Optimizations）

处理器和编译器为了使程序运行得更快，会施展各种“把戏”。例如，处理器可能会判断程序中两条特定的连续指令彼此不会产生影响，并（如果那样更快的话）乱序执行它们。当一条指令因为要从主内存获取某些数据而暂时阻塞时，只要不会改变程序的行为，后续的几条指令就可能会在这第一条指令完成之前被执行并完成。同样地，编译器如果有理由相信改变顺序或重写程序的某些部分可能导致更快的执行，它也可能会这样做。

但是，重申一遍，**只有在不会改变程序行为的前提下**，它们才会这么做。

让我们看下面这个函数作为例子：

```rust
fn f(a: &mut i32, b: &mut i32) {
    *a += 1;
    *b += 1;
    *a += 1;
}
```

在这里，编译器几乎肯定会理解这些操作的顺序无关紧要，因为在这三个加法操作之间，没有任何操作依赖于 `*a` 或 `*b` 的值。（假设溢出检查已禁用。）因此，它可能会重新排列第二个和第三个操作的顺序，然后将前两个合并为一次加法：

```rust
fn f(a: &mut i32, b: &mut i32) {
    *a += 2;
    *b += 1;
}
```

之后，在执行这个经过优化编译的程序函数时，处理器可能会因为各种原因，最终先执行第二个加法再执行第一个加法，可能是因为 `*b` 在缓存中可用，而 `*a` 必须从主内存中获取。

无论进行何种优化，结果保持不变：`*a` 增加 2，`*b` 增加 1。它们被增加的顺序对你的程序其余部分来说是完全不可见的。

验证特定重排序或其他优化是否会影响程序行为的逻辑**并未将其他线程考虑在内**。在我们上面的例子中，这完全没问题，因为唯一引用（`&mut i32`）保证了不可能有其他东西访问这些值，使得其他线程无关紧要。唯一会出现问题的情况是**当修改线程间共享的数据时**。或者换句话说，**在使用原子操作时**。这就是为什么我们必须明确地告诉编译器和处理器，它们能对我们的原子操作做什么、不能做什么，因为它们通常的逻辑忽略了线程间的交互，可能会允许那些确实会改变程序结果的优化。

有趣的问题是我们如何告知它们。如果我们想精确地说明什么是可以接受的、什么是不可以接受的，并发编程可能会变得极其冗长、容易出错，甚至可能依赖于特定架构：

```rust
let x = a.fetch_add(1,
Dear compiler and processor,
Feel free to reorder this with operations on b,but if there's another thread concurrently executing f,please don't reorder this with operations on c!
Also, processor, don't forget to flush your store buffer!If b is zero, though, it doesn't matter.
In that case, feel free to do whatever is fastest.
Thanks~ <3
);
```

相反，我们只能从一个小的选项集合中进行选择，这些选项由 `std::sync::atomic::Ordering` 枚举表示，每个原子操作都将其作为参数。可用的选项集非常有限，但经过精心挑选，能很好地适应大多数使用场景。这些排序选项非常抽象，并不直接反映所涉及的实际编译器和处理器机制，例如指令重排序。这使得你的并发代码能够做到与架构无关并经得起未来考验。它允许我们在不知道每一个现有及未来处理器和编译器版本细节的情况下进行验证。

Rust 中可用的排序选项有：
*   **宽松排序**：`Ordering::Relaxed`
*   **释放与获取排序**：`Ordering::{Release, Acquire, AcqRel}`
*   **顺序一致排序**：`Ordering::SeqCst`

在 C++ 中，还有一种称为**消费排序**的东西，它被有意地从 Rust 中省略了，但讨论一下也很有趣。

## **内存模型**（The Memory Model）

不同的内存排序选项有着严格的形式化定义，以确保我们确切地知道可以做出哪些假设，也让编译器开发者确切地知道他们需要为我们提供哪些保证。为了将其与特定处理器架构的细节解耦，内存排序是根据一个抽象的内存模型来定义的。

Rust 的内存模型（大部分借鉴自 C++）并不与任何现有的处理器架构完全匹配，而是一个抽象的模型，具有一组严格的规则。这些规则试图代表所有当前和未来架构的最大公约数，同时也给予编译器在分析和优化程序时足够的自由度，以做出有用的假设。

我们已经在第11页的“借用与数据竞争”一节中看到了内存模型的实际应用，在那里我们讨论了数据竞争如何导致未定义行为。Rust 的内存模型允许并发的原子存储，但将同一变量的并发非原子存储视为数据竞争，从而导致未定义行为。

然而，在大多数处理器架构上，原子存储和常规的非原子存储实际上并没有区别，这一点我们将在第7章中看到。可以说内存模型比实际需要的更严格，但这些严格的规则使得程序更易于推理，无论是对编译器还是对程序员而言都是如此，并且为未来的发展留下了空间。

## **Happens-Before关系**（Happens-Before Relationship）

内存模型根据**Happens-Before Relationship**来定义操作发生的顺序。这意味着，作为一个抽象模型，它不谈论机器指令、缓存、缓冲区、时序、指令重排序、编译器优化等等，而是只定义了一种情况：保证一件事在另一件事之前发生，而其他所有事情的顺序则不予定义。

基本的**Happens-Before**规则是：在同一线程内发生的一切都是按顺序发生的。如果一个线程执行 `f(); g();`，那么 `f()` 发生在 `g()` 之前。

然而，在线程之间，发生前关系只出现在几种特定情况中，例如创建和连接线程、解锁和锁定互斥锁，以及通过使用非宽松内存排序的原子操作。宽松内存排序是最基本（且性能最高）的内存排序，它本身永远不会导致任何跨线程的**Happens-Before**关系。

为了探究这意味着什么，让我们看看下面的例子，我们假设 `a` 和 `b` 由不同的线程并发执行：

```rust
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);

fn a() {
    X.store(10, Relaxed);
    Y.store(20, Relaxed);
}

fn b() {
    let y = Y.load(Relaxed);
    let x = X.load(Relaxed);
    println!("{x} {y}");
}
```

如上所述，基本的**Happens-Before**规则是：在同一线程内发生的一切都是按顺序发生的。在这个例子中：`X.store(10, Relaxed)` 发生在 `Y.store(20, Relaxed)` 之前，而 `Y.load(Relaxed)` 发生在 `X.load(Relaxed)` 之前，如图 3-1 所示。由于我们使用宽松内存排序，在我们的示例中没有其他的**Happens-Before**关系。

![figure-3-1](/img/rust-atomics-and-locks/chapter3/figure-3-1.png)

**图 3-1. 示例代码中原子操作之间的发生前关系**

如果 `a` 或 `b` 中的任何一个在另一个开始之前完成，那么输出将是 `0 0` 或 `10 20`。如果 `a` 和 `b` 并发运行，很容易看出输出可能是 `10 0`。发生这种情况的一种可能操作顺序如下：（此处省略具体顺序描述，但意指可能的交错执行导致此结果）。

### **创建与连接线程**（Spawning and Joining）

创建一个线程会在 `spawn()` 调用之前发生的事情和新线程之间建立**Happens-Before**关系。类似地，连接一个线程会在被连接的线程和 `join()` 调用之后发生的事情之间建立**Happens-Before**关系。

为了演示，以下示例中的断言不可能失败：

```rust
static X: AtomicI32 = AtomicI32::new(0);

fn main() {
    X.store(1, Relaxed);
    let t = thread::spawn(f);
    X.store(2, Relaxed);
    t.join().unwrap();
    X.store(3, Relaxed);
}

fn f() {
    let x = X.load(Relaxed);
    assert!(x == 1 || x == 2);
}
```

由于由连接和创建操作形成的**Happens-Before**关系，我们可以确定，对 `X` 的加载发生在第一次存储之后，但在最后一次存储之前，如图 3-2 所示。然而，它观察到的是第二次存储之前还是之后的值是不可预测的。换句话说，它可能加载到 1 或 2，但不会是 0 或 3。

![figure-3-2](/img/rust-atomics-and-locks/chapter3/figure-3-2.png)

**图 3-2. 示例代码中创建、连接、存储和加载操作之间的Happens-Before关系**

## **宽松排序**（Relaxed Ordering）

虽然使用宽松内存排序的原子操作不提供任何**发生前**关系，但它们确实保证了每个独立原子变量的**总修改顺序**。这意味着，从每一个线程的视角来看，对同一原子变量的所有修改都以相同的顺序发生。

为了说明这意味着什么，请考虑以下示例，我们假设 `a` 和 `b` 由不同的线程并发执行：

```rust
static X: AtomicI32 = AtomicI32::new(0);

fn a() {
    X.fetch_add(5, Relaxed);
    X.fetch_add(10, Relaxed);
}

fn b() {
    let a = X.load(Relaxed);
    let b = X.load(Relaxed);
    let c = X.load(Relaxed);
    let d = X.load(Relaxed);
    println!("{a} {b} {c} {d}");
}
```

在这个例子中，只有一个线程修改 `X`，这使得很容易看出 `X` 的修改顺序只有一种可能：0→5→15。它从零开始，然后变成五，最后被改为十五。线程不能观察到任何与这个总修改顺序不一致的 `X` 值。这意味着 `0 0 0 0`、`0 0 5 15` 和 `0 15 15 15` 是另一个线程中打印语句可能的一些结果，而 `0 5 0 15` 或 `0 0 10 15` 这样的输出是不可能的。

即使对于一个原子变量存在多个可能的修改顺序，所有线程也会就一个顺序达成一致。

让我们用两个独立的函数 `a1` 和 `a2` 替换 `a`，我们假设每个函数都由一个独立的线程执行：

```rust
fn a1() {
    X.fetch_add(5, Relaxed);
}

fn a2() {
    X.fetch_add(10, Relaxed);
}
```

假设这些是仅有的修改 `X` 的线程，那么现在有两种可能的修改顺序：要么是 0→5→15，要么是 0→10→15，这取决于哪个 `fetch_add` 操作先执行。无论发生哪种情况，所有线程都观察到相同的顺序。所以，即使我们有成百上千个额外线程都在运行我们的 `b()` 函数，我们知道如果其中一个打印出 10，那么顺序必须是 0→10→15，并且它们中没有一个可能打印出 5。反之亦然。

在第二章中，我们看到了几个用例示例，其中对单个变量的这种总修改顺序保证就足够了，使得宽松内存排序可以满足需求。然而，如果我们尝试超越这些例子进行更复杂的操作，很快就会看到我们需要比宽松内存排序更强的保证。

> **凭空出现的值**
>
> 当操作以循环方式相互依赖时，宽松内存排序缺乏顺序保证可能会导致一些理论上的复杂情况。
>
> 为了演示，这里有一个刻意设计的例子，两个线程从一个原子变量加载值并将其存储到另一个原子变量中：
>
>```rust
>static X: AtomicI32 = AtomicI32::new(0);
>static Y: AtomicI32 = AtomicI32::new(0);
>
>fn main() {
>    let a = thread::spawn(|| {
>        let x = X.load(Relaxed);
>        Y.store(x, Relaxed);
>    });
>    let b = thread::spawn(|| {
>        let y = Y.load(Relaxed);
>        X.store(y, Relaxed);
>    });
>    a.join().unwrap();
>    b.join().unwrap();
>    assert_eq!(X.load(Relaxed), 0); // 可能会失败？
>    assert_eq!(Y.load(Relaxed), 0); // 可能会失败？
>}
>```
>
>似乎很容易得出结论：`X` 和 `Y` 的值除了零之外永远不会是别的值，因为存储操作只存储从这些相同的原子变量加载的值，而这些值始终是零。
>
>然而，如果我们严格遵循理论上的内存模型，就不得不承认我们的循环推理，并得出一个可怕的结论：我们可能错了。事实上，从技术上讲，内存模型允许这样一种结果：最终 `X` 和 `Y` 都是 37，或者任何其他值，从而导致断言失败。
>
>由于缺乏顺序保证，这两个线程的加载操作可能都会看到另一个线程存储操作的结果，从而允许操作顺序中出现循环：我们将 37 存储到 `Y`，是因为我们从 `X` 加载了 37，而之所以将 37 存储到 `X`，是因为我们从 `Y` 加载了 37，而这个值正是我们存储到 `Y` 的。
>
>幸运的是，这种**凭空出现的值**的可能性被普遍认为是理论模型中的一个缺陷，而不是你在实践中需要考虑的问题。如何在不允许此类异常的情况下形式化宽松内存排序，这个理论问题尚未解决。虽然这对于形式化验证来说是个棘手的问题，让许多理论家夜不能寐，但我们其他人则可以幸福地无视这个问题，因为知道这在实践中不会发生。



## **释放与获取排序**（Release and Acquire Ordering）

释放与获取内存排序成对使用，以在线程间建立**发生前**关系。释放内存排序适用于存储操作，而获取内存排序适用于加载操作。

当一个获取-加载操作观察到释放-存储操作的结果时，就会形成**发生前**关系。在这种情况下，该存储操作以及它之前发生的所有操作，都发生在该加载操作以及它之后发生的所有操作之前。

当对获取-修改或比较并交换操作使用 `Acquire` 时，它仅适用于操作中加载值的部分。同样，`Release` 仅适用于操作中的存储部分。`AcqRel` 用于表示 `Acquire` 和 `Release` 的组合，这会导致加载使用获取排序，存储使用释放排序。

让我们看一个例子，了解这在实践中如何使用。在下面的例子中，我们从一个派生线程向主线程发送一个 64 位整数。我们使用一个额外的原子布尔值来告知主线程整数已被存储并准备就绪可供读取。

```rust
use std::sync::atomic::Ordering::{Acquire, Release};

static DATA: AtomicU64 = AtomicU64::new(0);
static READY: AtomicBool = AtomicBool::new(false);

fn main() {
    thread::spawn(|| {
        DATA.store(123, Relaxed);
        READY.store(true, Release); // 在此存储之前的所有操作 ...
    });
    while !READY.load(Acquire) { // ... 在此加载到 `true` 之后都可见。
        thread::sleep(Duration::from_millis(100));
        println!("waiting...");
    }
    println!("{}", DATA.load(Relaxed));
}
```

当派生线程完成数据存储后，它使用释放-存储将 `READY` 标志设置为 `true`。当主线程通过其获取-加载操作观察到这一点时，这两个操作之间就建立了一个**发生前**关系，如图 3-3 所示。此时，我们可以确定，在释放-存储到 `READY` 之前发生的所有操作，对于获取-加载之后发生的所有操作都是可见的。具体来说，当主线程从 `DATA` 加载时，我们可以确定它将加载后台线程存储的值。该程序在最后一行只能打印出一种可能的结果：`123`。

![figure-3-3](/img/rust-atomics-and-locks/chapter3/figure-3-3.png)

**图 3-3. 示例代码中原子操作之间的发生前关系，展示了通过获取和释放操作形成的跨线程关系**

如果在这个例子中我们对所有操作都使用宽松内存排序，主线程可能看到 `READY` 翻转为 `true`，但随后仍然从 `DATA` 加载到零。

> “释放”和“获取”的名称基于它们最基本的用例：一个线程通过原子地将某个值存储到原子变量中来**释放**数据，另一个线程通过原子地加载该值来**获取**它。这正是我们在一个线程上解锁（释放）互斥锁，随后在另一个线程上锁定（获取）它时所发生的情况。

在我们的例子中，来自 `READY` 标志的**发生前**关系保证了 `DATA` 的存储和加载操作不能并发发生。这意味着我们实际上并不需要这些操作是原子的。

然而，如果我们只是尝试对数据变量使用常规的非原子类型，编译器会拒绝我们的程序，因为 Rust 的类型系统不允许我们在另一个线程也在借用这些变量时从一个线程修改它们。类型系统不会神奇地理解我们在这里创建的**发生前**关系。需要一些不安全代码来向编译器承诺我们已经仔细考虑过这一点，并且确信我们没有违反任何规则，如下所示：

```rust
static mut DATA: u64 = 0;
static READY: AtomicBool = AtomicBool::new(false);

fn main() {
    thread::spawn(|| {
        // 安全性：没有其他代码在访问 DATA，因为我们还没有设置 READY 标志。
        unsafe { DATA = 123 };
        READY.store(true, Release); // 在此存储之前的所有操作 ...
    });
    while !READY.load(Acquire) { // ... 在此加载到 `true` 之后都可见。
        thread::sleep(Duration::from_millis(100));
        println!("waiting...");
    }
    // 安全性：没有代码在修改 DATA，因为 READY 已设置。
    println!("{}", unsafe { DATA });
}
```

>**更形式化地说明**
>
>当一个获取-加载操作观察到释放-存储操作的结果时，就形成了**发生前**关系。但这意味着什么？
>
>假设两个线程都向同一个原子变量释放-存储了一个值 `7`，而第三个线程从该变量加载了一个值 `7`。那么第三个线程现在是与第一个线程还是与第二个线程建立了**发生前**关系？这取决于它加载的是“哪个 `7`”：来自线程一的还是线程二的。（或者可能是一个无关的 `7`。）这使我们得出结论：即使 `7` 等于 `7`，来自两个线程的两个 `7` 也存在某种不同。
>
>思考这个问题的方式是借助我们在第 54 页“宽松排序”中讨论过的**总修改顺序**：发生在原子变量上的所有修改的有序列表。即使相同的值被多次写入同一个变量，这些操作中的每一个都代表了该变量总修改顺序中的一个独立事件。当我们加载一个值时，加载的值与这个按变量划分的“时间线”上的一个特定点相匹配，这告诉我们可能与哪个操作同步。
>
>例如，如果原子的总修改顺序是：
>1.  初始化为 0
>2.  释放-存储 7（来自线程二）
>3.  宽松-存储 6
>4.  释放-存储 7（来自线程一）
>
>那么获取-加载到一个 `7` 将与第二个事件中的释放-存储或最后一个事件中的释放-存储同步。然而，如果我们之前（根据**发生前**关系）看到过一个 `6`，我们就知道我们看到的是最后一个 `7`，而不是第一个，这意味着我们现在与线程一存在**发生前**关系，而不是与线程二。
>
>还有一个额外的细节是，释放-存储的值可能会被任意数量的获取-修改和比较并交换操作修改，但仍然会与读取最终结果的获取-加载操作产生**发生前**关系。
>
例如，假设一个原子变量具有以下总修改顺序：
>1.  初始化为 0
>2.  释放-存储 7
>3.  宽松-获取并加 1，将 7 变为 8
>4.  释放-获取并加 1，将 8 变为 9
>5.  释放-存储 7
>6.  宽松-交换 10，将 7 变为 10
>
>现在，如果我们从这个变量获取-加载一个 `9`，我们不仅与存储此值的第四个操作建立了**发生前**关系，还与存储了 `7` 的第二个操作建立了关系，即使第三个操作使用了宽松内存排序。
>
>类似地，如果我们从这个变量获取-加载一个 `10`，而这个值是由一个宽松操作写入的，我们仍然与第五个操作（它存储了一个 `7`）建立了**发生前**关系。因为那只是一个常规的存储操作（不是获取-修改或比较并交换操作），它打破了链条：我们不会与任何其他操作建立**发生前**关系。

### **示例：加锁**（Example: Locking）

互斥锁是释放和获取排序最常见的用例（见“锁定：Mutex 和 RwLock”）。锁定时，它们使用原子操作来检查是否已解锁，使用获取排序，同时（原子地）将状态更改为“已锁定”。解锁时，它们使用释放排序将状态设置回“未锁定”。这意味着在解锁互斥锁和随后锁定它之间会存在一个**发生前**关系。

以下是这种模式的演示：

```rust
static mut DATA: String = String::new();
static LOCKED: AtomicBool = AtomicBool::new(false);

fn f() {
    if LOCKED.compare_exchange(false, true, Acquire, Relaxed).is_ok() {
        // 安全性：我们持有独占锁，因此没有其他代码在访问 DATA。
        unsafe { DATA.push('!') };
        LOCKED.store(false, Release);
    }
}

fn main() {
    thread::scope(|s| {
        for _ in 0..100 {
            s.spawn(f);
        }
    });
}
```

正如我们在“比较并交换操作”中简要看到的，比较并交换操作接受两个内存排序参数：一个用于比较成功且存储发生的情况，另一个用于比较失败且存储未发生的情况。在 `f` 中，我们尝试将 `LOCKED` 从 `false` 更改为 `true`，并且仅在成功时访问 `DATA`。所以，我们只关心成功时的内存排序。如果 `compare_exchange` 操作失败，那一定是因为 `LOCKED` 已经被设置为 `true`，在这种情况下 `f` 什么都不做。这与常规互斥锁的 `try_lock` 操作相匹配。

>细心的读者可能已经注意到，比较并交换操作也可以是一个交换操作，因为在已锁定的情况下将 `true` 交换为 `true` 不会改变代码的正确性：
>
>```rust
>// 这样也可以。
>if LOCKED.swap(true, Acquire) == false { … }
>```

得益于获取和释放内存排序，我们可以确定没有两个线程可以并发访问 `DATA`。如图 3-4 所示，任何先前对 `DATA` 的访问都发生在后续向 `LOCKED` 释放-存储 `false` 之前，而后者又发生在下一个获取-比较并交换（或获取-交换）操作（将 `false` 更改为 `true`）之前，而该操作又发生在下一次访问 `DATA` 之前。

![figure-3-4](/img/rust-atomics-and-locks/chapter3/figure-3-4.png)

**图 3-4. 加锁示例中原子操作之间的发生前关系，展示了两个线程顺序加锁和解锁**

在[第4章]()中，我们将把这个概念转化为一个可重用的类型：自旋锁。

### **示例：带间接层的惰性初始化**（Example: Lazy Initialization with Indirection）

在“示例：惰性一次性初始化”中，我们实现了一个全局变量的惰性初始化，使用比较并交换操作来处理多个线程并发竞争初始化值的情况。因为该值是一个非零的 64 位整数，我们能够使用 `AtomicU64` 来存储它，在初始化之前使用零作为占位符。

要对无法放入单个原子变量的更大的数据类型进行相同的操作，我们需要寻找替代方案。

在这个例子中，假设我们想保持非阻塞行为，即线程永远不等待另一个线程，而是进行竞争并从第一个完成初始化的线程中取值。这意味着我们仍然需要能够通过单个原子操作从“未初始化”变为“完全初始化”。

正如软件工程的基本定理告诉我们的，计算机科学中的每个问题都可以通过添加另一层间接性来解决，这个问题也不例外。既然我们无法将数据放入单个原子变量中，我们可以改为使用原子变量来存储指向数据的指针。

`AtomicPtr<T>` 是 `*mut T` 的原子版本：一个指向 `T` 的指针。我们可以使用空指针作为初始状态的占位符，并使用比较并交换操作将其原子地替换为指向新分配的、完全初始化的 `T` 的指针，然后其他线程可以读取它。

由于我们不仅共享包含指针的原子变量，还共享它所指向的数据，因此我们不能再像第二章那样使用宽松内存排序。我们需要确保分配和初始化数据不会与读取数据产生竞争。换句话说，我们需要在存储和加载操作上使用释放和获取排序，以确保编译器和处理器不会破坏我们的代码，例如，通过重排序指针的存储和数据的初始化本身。

这引出了以下实现，针对某个名为 `Data` 的任意数据类型：

```rust
use std::sync::atomic::AtomicPtr;

fn get_data() -> &'static Data {
    static PTR: AtomicPtr<Data> = AtomicPtr::new(std::ptr::null_mut());

    let mut p = PTR.load(Acquire);

    if p.is_null() {
        p = Box::into_raw(Box::new(generate_data()));
        if let Err(e) = PTR.compare_exchange(
            std::ptr::null_mut(), p, Release, Acquire
        ) {
            // 安全性：p 来自上面的 Box::into_raw，且未与其他任何线程共享。
            drop(unsafe { Box::from_raw(p) });
            p = e;
        }
    }

    // 安全性：p 非空且指向已正确初始化的值。
    unsafe { &*p }
}
```

如果我们从 `PTR` 获取-加载的指针非空，我们假定它指向已初始化的数据，并构造一个指向该数据的引用。

然而，如果它仍然是空值，我们则生成新数据并使用 `Box::new` 将其存储在新的分配中。然后我们使用 `Box::into_raw` 将此 `Box` 转换为原始指针，以便我们可以尝试使用比较并交换操作将其存储到 `PTR` 中。如果另一个线程赢得了初始化竞争，因为 `PTR` 不再为空，`compare_exchange` 会失败。如果发生这种情况，我们将原始指针转回 `Box` 以便使用 `drop` 释放它，避免内存泄漏，并继续使用另一个线程存储在 `PTR` 中的指针。

最终不安全块中的安全注释说明了我们的假设：它指向的数据已经初始化。请注意，这包括一个关于事情发生顺序的假设。为了确保我们的假设成立，我们使用释放和获取内存排序来确保数据的初始化确实发生在创建对它的引用之前。

我们在两个地方加载一个可能非空（即已初始化）的指针：通过加载操作，以及通过 `compare_exchange` 操作失败时。因此，如上所述，我们需要对加载内存排序和 `compare_exchange` 失败内存排序都使用 `Acquire`，以便能够与存储指针的操作同步。该存储操作发生在 `compare_exchange` 操作成功时，因此我们必须使用 `Release` 作为其成功排序。

图 3-5 展示了三个线程调用 `get_data()` 时操作和发生前关系的可视化。在这种情况下，线程 A 和 B 都观察到空指针，并都尝试初始化原子指针。线程 A 赢得了竞争，导致线程 B 的 `compare_exchange` 操作失败。线程 C 在线程 A 初始化原子指针后才观察到它。最终结果是所有三个线程最终都使用了线程 A 分配的 `Box`。

![figure-3-5](/img/rust-atomics-and-locks/chapter3/figure-3-5.png)

**图 3-5. 三个线程调用 get_data() 时的操作和发生前关系**